# Ch3 Logistic regression and cross-validation


*Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.


```{r}
date()
```

Here we go yet again...

## Libraries used for Ch3

Obs! You might need to install some packages first if you haven't used them before (see install.packages()).
```{r, message=FALSE}
#install.packages(c("tidyverse","GGally","readr"))
```

Load the needed R packages before getting to work:
```{r, message=FALSE}
#load required packages
library(tidyverse)
library(GGally)
library(dplyr)
library(ggplot2)
```

## Data wrangling
See create_alc.R on [my Github repository](https://github.com/hsanez/IODS-project/tree/master/data/create_alc.R).


## Data analysis

### REPORT (Assignment 3)

**The purpose of this analysis is to study the relationships between high/low alcohol consumption and some of the other variables in our data.**

### 2. Read and describe the data

Read the analysis data.
```{r, message=FALSE}
# Read data (Make sure you're in the correct working folder with getwd())
alc <- read_csv("data/student_alc.csv")
# Alternative site for reading the data
#alc <- read_csv("https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/alc.csv")
```

Describe the data.
```{r, message=FALSE}
# print variable names and dimension of the tibble
colnames(alc); dim(alc)
```
The analysis dataset we are using for this course assignment consists of the above listed 35 variables and 370 observations.

Our analysis dataset is a subset of an original data *'Student Performance Data Set'* by Prof. Cortez (University of Minho, Portugal) collected from two Portuguese schools during the school year 2005-2006. The original dataset was collected using questionnaires and school reports.

The analysis dataset was created by joining two datasets of the original data; student data from two school subjects: Mathematics and Portuguese language.
These subject-specific datasets were merged by their common variables, and only students present in both subject datasets were included in the resulting analysis dataset. Naturally there was variation in the following time-related variables:

* failures = number of past class failures (numeric: n if 1<=n<3, else 4)
* paid = extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
* absences = number of school absences (numeric: from 0 to 93)
* G1 = first period grade (numeric: from 0 to 20)
* G2 = second period grade (numeric: from 0 to 20)
* G3 = final grade (numeric: from 0 to 20, output target)

For the numeric variables we calculated student-specific averages using both of the datasets (Mathematics and Portuguese language). For the binary variable (paid) we chose the value from the Mathematics dataset. 

See the [R code](https://github.com/hsanez/IODS-project/tree/master/data/create_alc.R) for the exact course of our data wrangling.

You can find the variable descriptions and more information about (and download) the original dataset on [this page](https://archive.ics.uci.edu/ml/datasets/Student+Performance).


### 3. Hypotheses on the relationships between alcohol consumption and chosen variables

My chosen variables:

* **age** = student's age (numeric: from 15 to 22)
* **sex** = student's sex (binary: 'F' - female or 'M' - male)
* **famrel** = quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
* **absences** = number of school absences (numeric: from 0 to 93)

The original dataset includes information on students from 15 to 22 years. This means all student's aren't of legal drinking age, [which seems to be 18 in Portugal](https://en.wikipedia.org/wiki/Legal_drinking_age). They won't be able to buy alcohol by themselves which could be seen in the relationship between age and alcohol use; there should be less alcohol use among younger students.

In average, men are larger than women, and their body composition differs, which makes their physiology and thus alcohol metabolism different from women's. This results in male tolerance for alcohol being usually better, which may lead to them drinking more before feeling the effects of alcohol. For this possible reason I think there might be a relationship between sex and alcohol use.

Students might spend a lot of time at home both studying or during their freetime. Thus, bad family relations could affect studying possibilities, motivation and recovering from studying. One reason for bad family relationships may be alcohol itself, maybe overused by the student itself or by other family members.

Students drinking more alcohol might have more absences from school. Since weekday alcohol consumption is measured it could be seen as absences during the school week. Friday or Saturday use might not come up as absences in the data, assuming that these schools in Portugal have a regular Monday to Friday school week schedule.


**My hypotheses:**

* More alcohol use among older students.
* More alcohol use among male students.
* More alcohol use among students with worse family relationships.
* More alcohol use among students with more school absences.




### 4. Descriptive analyses

```{r, message=FALSE}
# Load needed libraries
library(tidyr)
library(dplyr)
library(ggplot2)
library(GGally)

# glimpse at the data
glimpse(alc); dim(alc)

# create a vector of the chosen variables + alcohol use
myvars <- c('age', 'sex', 'famrel', 'absences', 'alc_use', 'high_use')

# pivot data and draw a bar plot of the chosen variables
gather(alc[myvars]) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()

# draw summary table grouped by sex and low/high use of alcohol consumption
alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_age = round(mean(age),1), mean_family_relation_quality = round(mean(famrel),1), mean_absences = round(mean(absences),1))

# draw summary plot matrix stratified for sex as an overview of the data and correlations
p <- ggpairs(alc[myvars], mapping = aes(col=sex, alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
p



```

* **Absences**:
  + Most students have either only a few (0-4) absences or very many (20-44) absences.
  + There is also a portion of students that have an average amount of absences (median=12).
  + Female students with high use of alcohol have the most absences.
  + Male students with no high alcohol use have the least amount of absences.
  + There seems to be a statistically significant positive correlation between alcohol use and absence (R=-0.123) regardless of sex.

* **Age**:
  + Students are between 15 and 22, most of them under 19.
  + The correlation analysis implies that there is a statistically significant positive correlation between age and alcohol use among male students.

* **Family relations**:
  + Most students seem to have good (4-5 on Likert scale) family relations.
  + Male students who don't use high amounts of alcohol seem to have the best family relations and it seems to correlate statistically significantly with alcohol use.

* **Alcohol use**:
  + There are more students who don't use high amounts of alcohol (n=259).
  + Most of students who don't use high amounts of alcohol are female students (n=154).
  + There are more male students who use high amounts of alcohol compared to female students (n=41).

* **Sex**:
  + There are more female (n=195) than male students (n=175).



* **My hypotheses:**
  + More alcohol use among older students. **-->** <span style="color:green">True</span> among male students!
  + More alcohol use among male students. **-->** <span style="color:green">True!</span>
  + More alcohol use among students with worse family relationships. **-->** <span style="color:green">True</span> among male students!
  + More alcohol use among students with more school absences. **-->** <span style="color:green">True! </span>
  
  
<center>
  
Nicely hypothesized - or - as *Jorma Uotinen* might say:

  
  ![](IODS-project_figs/ei-huono.jpg){width=35% height=50%}
  
</center>




### 5. Regression analyses
Our outcome variable is dichotomous, or binary, so we will assess its relationship with our chosen variables with a logistic regression model.

Dependent variable:

* High/low alcohol use (**high_use**) *(dichotomous)*

Independent variables:

* **age** *(numerical)*
* **sex** *(dichotomous)*
* quality of family relations (**famrel**) *(ordinal)*
* number of school absences (**absences**) *(numerical)*


```{r, message=FALSE}
library(dplyr); library(ggplot2)

# First, we define our logistic regression model m
# We'll use glm(), a generalized linear model function so we need to specify our model type to be logistic -> family="binomial", which makes the function use the link option 'logit'.
m <- glm(high_use ~ age + sex + famrel + absences, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# Compute odds ratios (OR) and their confidence intervals (CI) for each variable
OR <- coef(m) %>% exp %>% round(2)
CI <- confint(m) %>% exp %>% round(2)
# print ORs and CIs as a table
cbind(OR, CI)




```

* **Sex, Family relations and absences** seem to have a statistically significant association with high alcohol use (p<0.01).
* **Odds ratio** is $ e^{\beta}$
  + Male students have a 2.98 times the odds of using high amounts of alcohol compared to female students. The 95% confidence intervals are 1.8-4.9 (both above 1), which implies a statistically significant association.
  + Good family relations seem to be associated with less use of alcohol, the odds ratio is 0.72 (CI 0.6-0.9, both below 1) implying that good family relations are statistically significantly associated with a 28% (1-0.72) reduction on the risk of using high amounts of alcohol use.
  + Absences seem to be statistically significantly associated with high use of alcohol. The increase of school absences by one is associated with an increase of 9% in the odds of high alcohol use.
* **Age** has no statistically significant association with high level of alcohol use. 
  

* **My hypotheses:**
  + More alcohol use among older students. **-->** <span style="color:green">~~True~~</span> <span style="color:red"> WRONG </span> among male students!
  + More alcohol use among male students. **-->** <span style="color:green">True!</span>
  + More alcohol use among students with worse family relationships. **-->** <span style="color:green">True</span> among male students!
  + More alcohol use among students with more school absences. **-->** <span style="color:green">True! </span>


**In summary, three of my original hypothesis seem to stay valid after our correlation and regression analyses.**  


<center>

One hypothesis down! Oh no! But **no worries...**

  
  ![](IODS-project_figs/Its-okay-We-got-this.jpg){width=35% height=50%}
  
</center>






### 6. Predictive power of the model

To predict the power of our model we will create a ['confusion matrix'](https://en.wikipedia.org/wiki/Confusion_matrix), some graphs (bar plot, scatter plot and ROC curve), and compute the training error of the model. Finally we'll compare the performance of the model with a simple guessing strategy. Later, in [part 7](#7.-Bonus:-10-fold-cross-validation) of this report, we'll test the performance of the model with cross-validation.

As instructed, we'll use only the variables that showed statistical significance: **sex, famrel, absences**. Age had no statistically significant association with alcohol use level based on our regression model.


```{r}

# predict() the probability of high_use
# We're using our model 'm' as the object of the predict()
# type = 'response' defines that we want our prediction results on the scale of the response variable, instead of the default scale. This means that when dealing with a binomial target variable (e.g. our 'high_use') we will get our prediction results as predicted probabilities instead of logit-scaled probabilities (default for binomial ).
probabilities <- predict(m, type = "response")

library(dplyr)
# add the predicted probabilities to our dataframe 'alc' in a column named 'probability'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
# Let's set our prediction treshold: If the probability is more than 50%, prediction = TRUE, otherwise it's FALSE.
alc <- mutate(alc, prediction = probabilities >0.5)

# check the last ten original classes, predicted probabilities, and class predictions
select(alc, sex, famrel, absences, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% addmargins()
# transform to proportions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table() %>% addmargins() %>% round(2)

```
Almost one third of students drink alcohol an amount classifiable as 'high use' and our model underestimates the amount by predicting that only 11% of students use that much alcohol.


We can visualize our observations and predictions with a bar plot:

```{r, message=FALSE}
# initialize a plot of 'prediction' (predicted outcomes)
#basic colors
#p2 <- ggplot(data = alc, aes(x=prediction, col=prediction, fill=prediction))
# Custom colors
pred_colors <- c("#FFA500","#00FF00")
p2 <- ggplot(data = alc, aes(x=prediction, fill=prediction)) +
  scale_fill_manual(values=pred_colors)

# draw a bar plot of high_use by 'high use' (observations)
# delineate outcome variable labels
## define new labels
outlab <- c('True negative','True positive')
## Define old labels in same order
names(outlab) <- c('FALSE','TRUE')
p2 + geom_bar() + facet_wrap("high_use", labeller=labeller(high_use=outlab))

```
There are more FALSE observations (True negative observation = no high use of alcohol, left panel) than TRUE (True positive observation = high use of alcohol, right panel) observations. The prediction of true negative observations seems to be better than the prediction of true positive observations.

This can be presented also with a sleeker scatter plot:
```{r, message=FALSE}
# initialize a plot of 'high_use' versus 'probability' in 'alc'
p3 <- ggplot(alc, aes(x = probability, y = high_use, col=prediction))

# define the geom as points and draw the plot
p3 + geom_point()

```


--------------------------------------

We can also visualize our confusion matrix with a [ROC (receiver operating characteristic) curve](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc). This will show the performance of our classification model with the true positive and false positive rate.

We'll visualize the confusion matrix (sensitivity and specificity) with a [ROC (receiver operating characteristic) curve](https://www.statology.org/roc-curve-ggplot2/). This will help us assess how well our logistic regression model fits the dataset.

* Sensitivity = the probability that the model predicts a true positive outcome of the observations
* Specificity = the probability that the model predicts a true negative outcome of the observations (=1-FPR)

The ROC curve is constructed by plotting the true positive rate (TPR) against the false positive rate (FPR).

* TPR = TP/(TP+FN)
* FPR = FP/(TN+FP)

The closer the curve comes to the upper left corner of the plot, the more accurate the test is. THe closer to the grey 45' line the curve gets, the less accurate the test is.

```{r}
library(pROC)

# Define the curve with function roc(response, predictor), see ?roc() and pROC documentation (Resources)
roc_obj <- roc(alc$high_use, alc$probability)
# Draw the plot
plot(roc_obj)


```
We can see that the curve differs from the 45' curve, which means that our model seems to have at least some predictive value.


**Training error**

To calculate the training error (=the total proportion of inaccurately classified individuals) of our model, we'll run the loss function (mean prediction error) presented in our course exercises loss_func(response, probability). It will take into account a binomial response/classification variable ('high_use') and the probability of the response to be TRUE for each individual. 

* class is either TRUE (1) or FALSE (0) for our variable of interest ('high_use')
* prob (float between 0 and 1) is the individual probability that they are classified as TRUE for 'high_use'

abs() gives the absolute value of the difference between class and prob, so if it is >0.5, the prediction has been wrong.

The function assigns the logicals 'TRUE' or 'FALSE' depending on whether the model's prediction is false or true. **OBS!** The function assigns now 'TRUE' = 1, when the prediction has been false! Then it calculates the mean prediction error which is the number of false predictions divided by the number of total observations.

$$
\frac{n(FP + FN)*1 + n(TP + TN)*0}{N}
$$

The function:
```{r, message=FALSE}
# define the loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  # print(n_wrong) #print this if you want to see the logicals the final result mean() is based on
  mean(n_wrong)
}


# call loss_func() to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)

```


A simple guessing strategy might be just guessing that no student ever drinks enough for it to be classified as 'high use' (high_use = FALSE, probability(high_use=TRUE)= 0) or all drinking very much (high_use = TRUE, probability(high_use=TRUE) = 1) or that every other student drinks (probability(high_use=TRUE) = 0.5). These situations can be tested with the loss_func() by determining a constant individual probability (prob) as described above.

```{r, message=FALSE}

# No students' drinking habits are 'high use', high_use=FALSE, probability(high_use=TRUE)= 0
loss_func(class = alc$high_use, prob = 0)

# All students' drinking habits are 'high use', high_use=TRUE, probability(high_use=TRUE)= 1
loss_func(class = alc$high_use, prob = 1)

# Every other student's drinking habits are 'high use', high_use=TRUE, probability(high_use=TRUE)= 0.5
loss_func(class = alc$high_use, prob = 0.49)
loss_func(class = alc$high_use, prob = 0.51)

# Every third student's drinking habits are 'high use', high_use=TRUE, probability(high_use=TRUE)= 0.3
loss_func(class = alc$high_use, prob = 0.3)

```

The training error is 23.0%, which means that the models accuracy (1 - training error) is approximately 76%.
By simply guessing how many students' drinking habits are classified 'high use' we did not reach higher accuracy unless we guessed that every other students drinks:


Guess classified as 'high use'|Guessed probability of 'high use' drinking| Training error| Accuracy|
----:|:----------:|:-----------:|:-----------:|
No one drinks|0|0.3|70%|
Everybody drinks|1|0.7|30%|
Every other drinks*|0.49 & 0.51|0.3 & 0.7|70% & 30%|
Every third drinks|0.3|0.3|70%|

**OBS!**
*This assessment of exactly every other drinking (prob=0.50) can't be done since the function is defined with a 0.5 treshold. Thus the close approximates were used.


**In summary, our model seems to be better in predicting the level of alcohol use of our students than simple guessing.**




### 7. Bonus: 10-fold cross-validation

Quoted from our course material:
*[Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) is a method of testing a predictive model on unseen data. In cross-validation, the value of a penalty (loss) function (mean prediction error) is computed on data not used for finding the model. Low value = good.
Cross-validation gives a good estimate of the actual predictive power of the model. It can also be used to compare different models or classification methods.*

```{r}
# compute the average number of wrong predictions in the (training) data
loss_func(alc$high_use, alc$probability)

# K-fold cross-validation
library(boot)
cvK10 <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cvK10$delta[1]

```
The mean prediction error (0.25) combined from the rounds on the testing data seems to be a little bit lower than on the training data (0.24).

The model introduced in our Exercise set 3 had about 0.25 mean prediction error on the 10-fold cross validation on the testing data which implies that our new model (variables: sex, famrel, absences) has a similar test set performance to the one used in the Exercise set (variables: sex, failures, absences).





### 8. Super-Bonus: Comparison of logistic regression models with different sets of predictors

We'll do a comparison of 11 different testing models, substracting the number of predictors in each model by always keeping the most significant variables (dropping the last 5 variables then later excluding only one variable per model).


**Defining the models (logistic regression) and assigning predictions based on prediction probabilities **
```{r, message=FALSE, results=FALSE}
# check all possible variables
# -> 31 possible independent variables (we'll omit Daily and Weekend alcohol use since they were used for composing our outcome variable!)
colnames(alc)

# models and summaries
# detecting the least statistically significant variables
m1 <- glm(high_use ~  school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob + reason + guardian + traveltime + studytime + schoolsup + famsup + activities + nursery + higher + internet + romantic + famrel + freetime + goout + health + failures + paid + absences + G1 + G2 + G3 , data = alc, family ="binomial")
summary(m1)

piis <- summary(m1)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order: goout + famrel + absences + reason + sex + guardian + address + activities + freetime + Mjob + health + paid + famsize + romantic + Fjob + studytime + traveltime + nursery + failures + G1 + school + Fedu + G2 + age + Pstatus + G3 + higher + internet + famsup + Medu + schoolsup

m2 <- glm(high_use ~  goout + famrel + absences + reason + sex + guardian + address + activities + freetime + Mjob + health + paid + famsize + romantic + Fjob + studytime + traveltime + nursery + failures + G1 + school + Fedu + G2 + age + Pstatus + G3, data = alc, family ="binomial")
summary(m2)

piis <- summary(m2)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + absences + famrel + reason + sex + guardian + address + activities + freetime + Mjob + paid + health + famsize + studytime + traveltime + nursery + romantic + failures + G1 + school + Fjob + Fedu + G2 + age + Pstatus + G3

m3 <- glm(high_use ~  goout + absences + famrel + reason + sex + guardian + address + activities + paid + Mjob + health + freetime + famsize + romantic + studytime + Fjob + traveltime + nursery + school + failures + G1, data = alc, family ="binomial")
summary(m3)

piis <- summary(m3)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + absences + famrel + reason + sex + guardian + address + activities + paid + Mjob + health + freetime + famsize + romantic + studytime + Fjob + traveltime + nursery + school + failures + G1


m4 <- glm(high_use ~  goout + absences + famrel + reason + sex + guardian + address + activities + paid + Mjob + health + freetime + famsize + romantic + studytime + Fjob, data = alc, family ="binomial")
summary(m4)

piis <- summary(m4)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + absences + famrel + sex + reason + address + guardian + health + Mjob + studytime + activities + paid + famsize + romantic + Fjob + freetime


m5 <- glm(high_use ~  goout + absences + famrel + sex + reason + address + guardian + health + Mjob + studytime + activities, data = alc, family ="binomial")
summary(m5)

piis <- summary(m5)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + absences + famrel + sex + reason + guardian + address + activities + studytime + health + Mjob


m6 <- glm(high_use ~  goout + absences + famrel + sex + reason + guardian, data = alc, family ="binomial")
summary(m6)

piis <- summary(m6)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + sex + absences + famrel + reason + guardian


m7 <- glm(high_use ~  goout + sex + absences + famrel + reason, data = alc, family ="binomial")
summary(m7)

piis <- summary(m7)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + sex + absences + famrel + reason


m8 <- glm(high_use ~  goout + sex + absences + famrel, data = alc, family ="binomial")
summary(m8)

piis <- summary(m8)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + sex + absences + famrel


m9 <- glm(high_use ~  goout + sex + absences, data = alc, family ="binomial")
summary(m9)

piis <- summary(m9)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + sex + absences


m10 <- glm(high_use ~  goout + sex, data = alc, family ="binomial")
summary(m10)

piis <- summary(m10)[12]
piis.sort <- as.data.frame(piis)
names(piis.sort) <- c("Estimate","SE","Tval","Pval")
psort <- arrange(piis.sort,Pval)
# sorted order:  goout + sex 


m11 <- glm(high_use ~  goout, data = alc, family ="binomial")
summary(m11)



# predict() the probability of high_use
probabilities1 <- predict(m1, type = "response")
probabilities2 <- predict(m2, type = "response")
probabilities3 <- predict(m3, type = "response")
probabilities4 <- predict(m4, type = "response")
probabilities5 <- predict(m5, type = "response")
probabilities6 <- predict(m6, type = "response")
probabilities7 <- predict(m7, type = "response")
probabilities8 <- predict(m8, type = "response")
probabilities9 <- predict(m9, type = "response")
probabilities10 <- predict(m10, type = "response")
probabilities11 <- predict(m11, type = "response")

# add the predicted probabilities to our dataframe 'alc' in a column named 'probability'
alc <- mutate(alc, probability1 = probabilities1)
alc <- mutate(alc, probability2 = probabilities2)
alc <- mutate(alc, probability3 = probabilities3)
alc <- mutate(alc, probability4 = probabilities4)
alc <- mutate(alc, probability5 = probabilities5)
alc <- mutate(alc, probability6 = probabilities6)
alc <- mutate(alc, probability7 = probabilities7)
alc <- mutate(alc, probability8 = probabilities8)
alc <- mutate(alc, probability9 = probabilities9)
alc <- mutate(alc, probability10 = probabilities10)
alc <- mutate(alc, probability11 = probabilities11)

# use the probabilities to make a prediction of high_use
# Let's set our prediction treshold: If the probability is more than 50%, prediction = TRUE, otherwise it's FALSE.
alc <- mutate(alc, prediction1 = probabilities1 >0.5)
alc <- mutate(alc, prediction2 = probabilities2 >0.5)
alc <- mutate(alc, prediction3 = probabilities3 >0.5)
alc <- mutate(alc, prediction4 = probabilities4 >0.5)
alc <- mutate(alc, prediction5 = probabilities5 >0.5)
alc <- mutate(alc, prediction6 = probabilities6 >0.5)
alc <- mutate(alc, prediction7 = probabilities7 >0.5)
alc <- mutate(alc, prediction8 = probabilities8 >0.5)
alc <- mutate(alc, prediction9 = probabilities9 >0.5)
alc <- mutate(alc, prediction10 = probabilities10 >0.5)
alc <- mutate(alc, prediction11 = probabilities11 >0.5)



```
The order of the variables (p-value) changed between regressions. However, the 'top' variables' significance stayed and they kept their top positions on the regression summaries through all the regressions. The less significant variables changed rankings often, and thus they happened to be the ones to primarily get discarded from the model.


<center>

**Nota bene!**

I didn't get my for-loops nor dynamic functions to work so part 8 scripts have been <ins> and will continue being</ins> ugly...sorry! But **don't worry**, since...

  
  ![*Kittycat suffering from ugly-scriptitis*](IODS-project_figs/its-okay-youre-gonna.jpg){width=30% height=100%}


</center>


**Training and testing errors by model**
```{r, message=FALSE}

# Models numbered by amount of variables used
modelss <- c(31,26,21,16,11,6,5,4,3,2,1)

# call loss_func() to compute the average number of wrong predictions in the (training) data
pred_train <- loss_func(class = alc$high_use, prob = alc$probability1)
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability2))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability3))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability4))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability5))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability6))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability7))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability8))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability9))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability10))
pred_train <- append(pred_train, loss_func(class = alc$high_use, prob = alc$probability11))

#10-fold cross validation on testing data
cvK10_ss1 <- cv.glm(data = alc, cost = loss_func, glmfit = m1, K = 10)
cvK10_ss2 <- cv.glm(data = alc, cost = loss_func, glmfit = m2, K = 10)
cvK10_ss3 <- cv.glm(data = alc, cost = loss_func, glmfit = m3, K = 10)
cvK10_ss4 <- cv.glm(data = alc, cost = loss_func, glmfit = m4, K = 10)
cvK10_ss5 <- cv.glm(data = alc, cost = loss_func, glmfit = m5, K = 10)
cvK10_ss6 <- cv.glm(data = alc, cost = loss_func, glmfit = m6, K = 10)
cvK10_ss7 <- cv.glm(data = alc, cost = loss_func, glmfit = m7, K = 10)
cvK10_ss8 <- cv.glm(data = alc, cost = loss_func, glmfit = m8, K = 10)
cvK10_ss9 <- cv.glm(data = alc, cost = loss_func, glmfit = m9, K = 10)
cvK10_ss10 <- cv.glm(data = alc, cost = loss_func, glmfit = m10, K = 10)
cvK10_ss11 <- cv.glm(data = alc, cost = loss_func, glmfit = m11, K = 10)


# average number of wrong predictions in the cross validation
cvK10$delta[1]
cvK10_ss <- cvK10_ss1$delta[1]
cvK10_ss <- append(cvK10_ss,cvK10_ss2$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss3$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss4$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss5$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss6$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss7$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss8$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss9$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss10$delta[1])
cvK10_ss <- append(cvK10_ss,cvK10_ss11$delta[1])


# create a tibble
supbon <- tibble(modelss, pred_train, cvK10_ss)

```


Trends of both training and testing errors by the number of predictors in the model
```{r, message=FALSE}
# Pivot data
longdf <- pivot_longer(supbon, c('pred_train','cvK10_ss'))

# initialize and draw a plot
ggplot(data=longdf, aes(x=modelss, y=value, col=name)) + geom_point() + geom_line() +
  # Edit legend title and labels
  scale_color_discrete(name = "Mean prediction error", labels = c("testing", "training")) +
  # Edit label names and title
  labs(x="Model", title='Trends of training and testing errors by the number of predictors in the model')

```

**The mean prediction error is:**

* always lower in the training set.
* very high in both the testing and training set when the model has only 1-2 predictors.
* quite low in both the testing and training set when the model has 3-5 predictors.
* quite high in both sets when there are 6-16 predictors in the model.
* low in the training set and very high in the testing set when there are 21-31 predictors in the model.

$\rightarrow$ **The predictive logarithmic regression model is at its best with not too few nor too many variables** $\rightarrow$ 3-5 variables seems like a good option for model construction.




&check; &check; &check; &check; &check; &check; &check; &check; &check; Done!





## Resources

* [Wikipedia on drinking age](https://en.wikipedia.org/wiki/Legal_drinking_age).
* [Sorting regression summaries](https://stackoverflow.com/questions/17483462/regression-summaries-in-r)
* [Pivot data from wide to long with pivot_long(), a "new version" of gather()](https://tidyr.tidyverse.org/reference/pivot_longer.html)
* [Pic of Jorma Uotinen](https://makemyhair.munblogi.com/files/2015/08/maxresdefault.jpg)
* [Nice help with logaritmic regression interpretation](https://quantifyinghealth.com/interpret-logistic-regression-coefficients/)
* [On interpretation of categorical variables in regression analysis](https://stats.stackexchange.com/questions/60817/significance-of-categorical-predictor-in-logistic-regression)
* [We go this -meme](https://memeshappen.com/meme/77815/Its-okay)
* [ggplot2 facet labeling changes](https://www.datanovia.com/en/blog/how-to-change-ggplot-facet-labels/)
* [ggplot2 label and legend changes](https://www.datanovia.com/en/blog/ggplot-legend-title-position-and-labels/)
* [ggplot2 cheat sheet](https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Misc/data-visualization-2.1.pdf)
* [Poor cat suffering from ugly-scriptitis](https://makeameme.org/meme/its-okay-youre-4420ef7cf7)


```{r, message=FALSE}

```



